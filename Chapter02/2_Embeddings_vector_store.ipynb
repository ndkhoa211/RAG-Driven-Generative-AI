{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding-Based Retrieval with ChromaDB and OpenAI\n",
    "\n",
    "This notebook creates embeddings from text data and stores them in a local ChromaDB vector store.\n",
    "\n",
    "**Features:** Auto-refresh on each run | Local storage | Batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  API Key: sk-proj-lq...\n",
      "  Collection: space_exploration\n",
      "  Storage: ./chroma_db\n",
      "  Query results: 10\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configuration\n",
    "CHUNK_SIZE = 1000\n",
    "BATCH_SIZE = 100\n",
    "COLLECTION_NAME = \"space_exploration\"\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "SOURCE_FILE = \"llm.txt\"\n",
    "N_RESULTS = 10  # Number of results to return from queries\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  API Key: {openai.api_key[:10]}...\")\n",
    "print(f\"  Collection: {COLLECTION_NAME}\")\n",
    "print(f\"  Storage: {CHROMA_PATH}\")\n",
    "print(f\"  Query results: {N_RESULTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Chunk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loaded and chunked\n",
      "  File size: 1,144,194 characters\n",
      "  Total chunks: 1145\n",
      "  Chunk size: 1000 characters\n"
     ]
    }
   ],
   "source": [
    "# Load text file\n",
    "if not os.path.exists(SOURCE_FILE):\n",
    "    raise FileNotFoundError(f\"{SOURCE_FILE} not found. Run 1_Data_collection_preparation.ipynb first.\")\n",
    "\n",
    "with open(SOURCE_FILE, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Create chunks\n",
    "chunks = [text[i:i+CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]\n",
    "\n",
    "print(f\"✓ Data loaded and chunked\")\n",
    "print(f\"  File size: {len(text):,} characters\")\n",
    "print(f\"  Total chunks: {len(chunks)}\")\n",
    "print(f\"  Chunk size: {CHUNK_SIZE} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup ChromaDB Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Deleted existing collection\n",
      "✓ Collection 'space_exploration' created\n"
     ]
    }
   ],
   "source": [
    "# Initialize ChromaDB client\n",
    "client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "# Delete existing collection and create fresh one\n",
    "try:\n",
    "    client.delete_collection(name=COLLECTION_NAME)\n",
    "    print(f\"✓ Deleted existing collection\")\n",
    "except:\n",
    "    print(f\"  No existing collection to delete\")\n",
    "\n",
    "# Create fresh collection\n",
    "collection = client.create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    metadata={\"description\": \"Space exploration articles from Wikipedia\"}\n",
    ")\n",
    "\n",
    "print(f\"✓ Collection '{COLLECTION_NAME}' created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1145 chunks in batches of 100...\n",
      "\n",
      "  ✓ Processed 100/1145 chunks\n",
      "  ✓ Processed 200/1145 chunks\n",
      "  ✓ Processed 300/1145 chunks\n",
      "  ✓ Processed 400/1145 chunks\n",
      "  ✓ Processed 500/1145 chunks\n",
      "  ✓ Processed 600/1145 chunks\n",
      "  ✓ Processed 700/1145 chunks\n",
      "  ✓ Processed 800/1145 chunks\n",
      "  ✓ Processed 900/1145 chunks\n",
      "  ✓ Processed 1000/1145 chunks\n",
      "  ✓ Processed 1100/1145 chunks\n",
      "  ✓ Processed 1145/1145 chunks\n",
      "\n",
      "✓ All chunks stored in vector database\n",
      "  Total documents: 1145\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"Get embeddings from OpenAI\"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    texts = [t.replace(\"\\n\", \" \") for t in texts]\n",
    "    response = openai.embeddings.create(input=texts, model=model)\n",
    "    return [data.embedding for data in response.data]\n",
    "\n",
    "# Process chunks in batches\n",
    "print(f\"Processing {len(chunks)} chunks in batches of {BATCH_SIZE}...\\n\")\n",
    "\n",
    "for batch_start in range(0, len(chunks), BATCH_SIZE):\n",
    "    batch_end = min(batch_start + BATCH_SIZE, len(chunks))\n",
    "    batch = chunks[batch_start:batch_end]\n",
    "    \n",
    "    # Generate IDs, embeddings, and metadata\n",
    "    ids = [f\"chunk_{i}\" for i in range(batch_start, batch_end)]\n",
    "    embeddings = get_embeddings(batch)\n",
    "    metadatas = [{\"source\": SOURCE_FILE, \"chunk_id\": i} for i in range(batch_start, batch_end)]\n",
    "    \n",
    "    # Add to ChromaDB\n",
    "    collection.add(ids=ids, documents=batch, embeddings=embeddings, metadatas=metadatas)\n",
    "    \n",
    "    print(f\"  ✓ Processed {batch_end}/{len(chunks)} chunks\")\n",
    "\n",
    "print(f\"\\n✓ All chunks stored in vector database\")\n",
    "print(f\"  Total documents: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the International Space Station?\n",
      "Requested results: 10\n",
      "Actual results returned: 10\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Result 1 (distance: 0.5572):\n",
      " Programare:\n",
      "\n",
      "TheInternational Space Station(ISS) is a largespace stationthat wasassembledand is maintained inlow Earth orbitby a collaboration of five space agencies and their contractors:NASA(United...\n",
      "\n",
      "Result 2 (distance: 0.7319):\n",
      " architectures and associated timelines relevant to lunar and Mars exploration and science. TheInternational Space Station(ISS) combines NASA'sSpace StationFreedomproject with the RussianMir-2station,...\n",
      "\n",
      "Result 3 (distance: 0.7457):\n",
      "n Space Agency's headquarters inSaint-Hubert, Quebec. The ISS is currently maintained in a nearly circular orbit with a minimum mean altitude of 370 km (230 mi) and a maximum of 460 km (290 mi),in the...\n",
      "\n",
      "Result 4 (distance: 0.7488):\n",
      "arth at an average altitude of 400 kilometres (250 miles)and circles the Earth in roughly 93 minutes, completing 15.5 orbits per day. TheISS programmecombines two previously planned crewed Earth-orbit...\n",
      "\n",
      "Result 5 (distance: 0.8097):\n",
      "uts from15 different nations. The station can be seen from the Earth with the naked eye and, as of 2025, is the largest artificial satellite in Earth orbit with a mass and volume greater than that of ...\n",
      "\n",
      "Result 6 (distance: 0.8436):\n",
      "xation or catching up on tasks. Free time often involves enjoying personal hobbies, communicating with family, or gazing out at Earth through the station's windows.The crew can watch TV aboard the sta...\n",
      "\n",
      "Result 7 (distance: 0.8511):\n",
      "and ISS are all positioned approximately in a single line) are of particular interest for amateur astronomers. Gravity at the altitude of the ISS is approximately 90% as strong as at Earth's surface, ...\n",
      "\n",
      "Result 8 (distance: 0.8558):\n",
      "bed as themost expensive single itemever constructed.As of 2010, the total cost was US$150 billion. This includesNASA's budget of $58.7 billion ($89.73 billion in 2021 dollars) for the station from 19...\n",
      "\n",
      "Result 9 (distance: 0.8584):\n",
      ", but space stations offer a long-term environment where studies can be performed potentially for decades, combined with ready access by human researchers. The ISS simplifies individual experiments by...\n",
      "\n",
      "Result 10 (distance: 0.8761):\n",
      " specifically for Wikipedia. In November 2021, avirtual realityexhibit called The Infinite featuring life aboard the ISS was announced. Involving five space programs and fifteen countries,the Internat...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the vector store with a sample query\n",
    "test_query = \"What is the International Space Station?\"\n",
    "query_embedding = get_embeddings([test_query])[0]\n",
    "\n",
    "results = collection.query(query_embeddings=[query_embedding], n_results=N_RESULTS)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Requested results: {N_RESULTS}\")\n",
    "print(f\"Actual results returned: {len(results['documents'][0])}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(len(results['documents'][0])):\n",
    "    doc = results['documents'][0][i]\n",
    "    dist = results['distances'][0][i]\n",
    "    print(f\"\\nResult {i+1} (distance: {dist:.4f}):\")\n",
    "    print(f\"{doc[:200]}...\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Understanding Embeddings and Distance Metrics\n\n### What are Embeddings?\n\nAn **embedding** is a vector representation of text in high-dimensional space. Each text chunk is converted to a vector:\n\n$$\\mathbf{v} = [v_1, v_2, v_3, \\ldots, v_{1536}] \\in \\mathbb{R}^{1536}$$\n\nWhere:\n- $\\mathbf{v}$ is the embedding vector\n- Each $v_i$ is a real number (typically between -0.1 and 0.1)\n- The dimension is 1536 for the `text-embedding-3-small` model\n\n**Example:** When we show `[-0.0077, -0.0326, 0.0752, ...]`, these are the first few components of the 1536-dimensional vector.\n\n### Understanding Embedding Value Statistics\n\nWhen we analyze embedding statistics, we're looking at the **distribution of the 1536 values** within each vector:\n\n**Mean of embedding values:**\n$$\\mu = \\frac{1}{1536} \\sum_{i=1}^{1536} v_i$$\n\n- **Interpretation:** Average value across all dimensions\n- **Typical value:** Close to 0 (embeddings are normalized)\n- **Insight:** If mean $\\approx 0$, the embedding is balanced (not biased toward positive/negative)\n\n**Standard deviation:**\n$$\\sigma = \\sqrt{\\frac{1}{1536} \\sum_{i=1}^{1536} (v_i - \\mu)^2}$$\n\n- **Interpretation:** How spread out the values are across dimensions\n- **Typical value:** 0.02-0.04 for normalized embeddings\n- **Insight:** Higher std = more varied features; Lower std = more concentrated representation\n\n**Min/Max values:**\n- **Interpretation:** The range of values in the vector\n- **Typical range:** [-0.1, 0.1] after normalization\n- **Insight:** Shows if any dimension has unusually strong activation (outlier features)\n\n### How Distance Works\n\n**Distance** measures semantic similarity between two embeddings using **Euclidean distance**:\n\n$$d(\\mathbf{v}_1, \\mathbf{v}_2) = \\sqrt{\\sum_{i=1}^{1536} (v_{1,i} - v_{2,i})^2}$$\n\n**Interpretation:**\n- $d = 0$: Identical embeddings\n- $d < 0.5$: Very similar content\n- $0.5 \\leq d < 1.0$: Moderately similar\n- $d \\geq 1.0$: Less similar or unrelated\n\n### Practical Insight\n\nWhen you query the vector database:\n1. Your query text → embedding vector $\\mathbf{q} \\in \\mathbb{R}^{1536}$\n2. Calculate $d(\\mathbf{q}, \\mathbf{v}_i)$ for each stored chunk\n3. Results ranked by distance (lowest = most relevant)\n\n**Why statistics matter:** Embeddings with similar statistics (mean, std) tend to represent similar types of content. Outlier values (unusually high/low) indicate unique semantic features."
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VECTOR STORE SUMMARY\n",
      "================================================================================\n",
      "Collection: space_exploration\n",
      "Total documents: 1145\n",
      "Storage path: ./chroma_db\n",
      "Storage size: 58.63 MB\n",
      "Metadata: {'description': 'Space exploration articles from Wikipedia'}\n",
      "================================================================================\n",
      "\n",
      "SAMPLE RETRIEVED DOCUMENTS (Top 10 from semantic search):\n",
      "================================================================================\n",
      "Query: 'space exploration and missions'\n",
      "Retrieving top 10 most similar chunks by vector distance\n",
      "\n",
      "--- Result 1: chunk_0 (distance: 0.6388) ---\n",
      "Text: Space explorationis the physical investigation ofouter spacebyuncrewed robotic space probesand throughhuman spaceflight. While the observation of objects in space, known asastronomy, predates reliable...\n",
      "Embedding vector (first 5 of 1536 dims): ['-0.0077', '-0.0325', '0.0753', '0.0074', '0.0128']\n",
      "\n",
      "--- Result 2: chunk_733 (distance: 0.7296) ---\n",
      "Text: t based on the HALO-module for the Gateway station. NASA has conducted many uncrewed and robotic spaceflight programs throughout its history. More than 1,000 uncrewed missions have been designed to ex...\n",
      "Embedding vector (first 5 of 1536 dims): ['-0.0166', '-0.0181', '0.1150', '-0.0148', '0.0225']\n",
      "\n",
      "--- Result 3: chunk_23 (distance: 0.7868) ---\n",
      "Text: issionreturned samples of another comet's tail. ThePhilaelandersuccessfully landed onComet Churyumov–Gerasimenkoin 2014 as part of the broaderRosettamission. Deep space exploration is the branch ofast...\n",
      "Embedding vector (first 5 of 1536 dims): ['0.0205', '-0.0275', '0.0666', '0.0051', '-0.0128']\n",
      "\n",
      "--- Result 4: chunk_29 (distance: 0.8150) ---\n",
      "Text: del for efforts in space exploration well into the twenty-first century, with NASA incorporating this approach into the majority of their projects.The steps were followed out of order, as seen by the ...\n",
      "Embedding vector (first 5 of 1536 dims): ['0.0170', '-0.0165', '0.0696', '-0.0022', '0.0418']\n",
      "\n",
      "--- Result 5: chunk_737 (distance: 0.8259) ---\n",
      "Text: see Discovery, New Frontiers, etc.). TheJames Webb Space Telescopeis a strategic mission that was developed over a period of more than 20 years. Strategic missions are developed on an ad-hoc basis as ...\n",
      "Embedding vector (first 5 of 1536 dims): ['-0.0260', '0.0111', '0.0524', '-0.0211', '-0.0209']\n",
      "\n",
      "--- Result 6: chunk_782 (distance: 0.8308) ---\n",
      "Text: spirators): 1) anicy moonsample return mission and 2)human space exploration.In early 2025, ESA released its \"Strategy 2040\", a long-term roadmap adopted by the ESA council to define the agency's prio...\n",
      "Embedding vector (first 5 of 1536 dims): ['-0.0257', '-0.0069', '0.0685', '-0.0100', '-0.0100']\n",
      "\n",
      "--- Result 7: chunk_734 (distance: 0.8413) ---\n",
      "Text:  provides frequent flight opportunities for moderate cost innovative solutions from the heliophysics and astrophysics science areas. The Small Explorer missions are required to limit cost to NASA to b...\n",
      "Embedding vector (first 5 of 1536 dims): ['0.0038', '-0.0492', '0.0772', '-0.0209', '-0.0212']\n",
      "\n",
      "--- Result 8: chunk_30 (distance: 0.8571) ---\n",
      "Text: e flight ofspacecraftinto and through outer space. Spaceflight is used in space exploration, and also in commercial activities likespace tourismandsatellite telecommunications. Additional non-commerci...\n",
      "Embedding vector (first 5 of 1536 dims): ['0.0248', '-0.0252', '0.0741', '-0.0282', '0.0218']\n",
      "\n",
      "--- Result 9: chunk_780 (distance: 0.8652) ---\n",
      "Text:  and 2024. The beginning of the new millennium saw the ESA become, along with agencies likeNASAandJAXA, one of the major participants inspace research. Although ESA had relied on co-operation with NAS...\n",
      "Embedding vector (first 5 of 1536 dims): ['-0.0459', '-0.0258', '0.0961', '-0.0251', '0.0063']\n",
      "\n",
      "--- Result 10: chunk_787 (distance: 0.8713) ---\n",
      "Text: f life on Earth. They want greater security and economic wealth, but they also want to pursue their dreams, to increase their knowledge, and they want younger people to be attracted to the pursuit of ...\n",
      "Embedding vector (first 5 of 1536 dims): ['0.0219', '0.0168', '0.0800', '0.0201', '0.0280']\n",
      "\n",
      "================================================================================\n",
      "\n",
      "EMBEDDING STATISTICS:\n",
      "================================================================================\n",
      "Model: text-embedding-3-small\n",
      "Dimensions: 1536\n",
      "Documents analyzed: 10\n",
      "Value range: [-0.1168, 0.1201]\n",
      "Mean: -0.000147\n",
      "Std deviation: 0.025515\n",
      "================================================================================\n",
      "\n",
      "DATABASE METADATA:\n",
      "================================================================================\n",
      "Total chunks: 1145\n",
      "Chunk range: 0 to 1144\n",
      "Source: llm.txt\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate storage size\n",
    "def get_dir_size(path):\n",
    "    total = 0\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.exists(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "# Display summary\n",
    "print(\"=\"*80)\n",
    "print(\"VECTOR STORE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Collection: {collection.name}\")\n",
    "print(f\"Total documents: {collection.count()}\")\n",
    "print(f\"Storage path: {CHROMA_PATH}\")\n",
    "\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "    size = get_dir_size(CHROMA_PATH)\n",
    "    print(f\"Storage size: {size / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(f\"Metadata: {collection.metadata}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show sample documents retrieved by semantic search\n",
    "print(f\"\\nSAMPLE RETRIEVED DOCUMENTS (Top {N_RESULTS} from semantic search):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Perform a sample query to get actual retrieved documents\n",
    "sample_query = \"space exploration and missions\"\n",
    "sample_query_embedding = get_embeddings([sample_query])[0]\n",
    "sample_results = collection.query(\n",
    "    query_embeddings=[sample_query_embedding],\n",
    "    n_results=N_RESULTS,\n",
    "    include=[\"documents\", \"metadatas\", \"embeddings\", \"distances\"]\n",
    ")\n",
    "\n",
    "print(f\"Query: '{sample_query}'\")\n",
    "print(f\"Retrieving top {N_RESULTS} most similar chunks by vector distance\\n\")\n",
    "\n",
    "for i in range(len(sample_results['ids'][0])):\n",
    "    chunk_id = sample_results['ids'][0][i]\n",
    "    doc = sample_results['documents'][0][i]\n",
    "    distance = sample_results['distances'][0][i]\n",
    "    embedding = sample_results['embeddings'][0][i]\n",
    "    \n",
    "    print(f\"--- Result {i+1}: {chunk_id} (distance: {distance:.4f}) ---\")\n",
    "    print(f\"Text: {doc[:200]}...\")\n",
    "    print(f\"Embedding vector (first 5 of {len(embedding)} dims): {[f'{x:.4f}' for x in embedding[:5]]}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show embedding statistics\n",
    "print(\"\\nEMBEDDING STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_embeddings = sample_results['embeddings'][0]\n",
    "embeddings_array = np.array(all_embeddings)\n",
    "\n",
    "print(f\"Model: text-embedding-3-small\")\n",
    "print(f\"Dimensions: {embeddings_array.shape[1]}\")\n",
    "print(f\"Documents analyzed: {embeddings_array.shape[0]}\")\n",
    "print(f\"Value range: [{embeddings_array.min():.4f}, {embeddings_array.max():.4f}]\")\n",
    "print(f\"Mean: {embeddings_array.mean():.6f}\")\n",
    "print(f\"Std deviation: {embeddings_array.std():.6f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show metadata distribution across entire database\n",
    "print(\"\\nDATABASE METADATA:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_data = collection.get(include=[\"metadatas\"])\n",
    "chunk_ids = [m['chunk_id'] for m in all_data['metadatas']]\n",
    "\n",
    "print(f\"Total chunks: {len(chunk_ids)}\")\n",
    "print(f\"Chunk range: 0 to {max(chunk_ids)}\")\n",
    "print(f\"Source: {all_data['metadatas'][0]['source']}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}