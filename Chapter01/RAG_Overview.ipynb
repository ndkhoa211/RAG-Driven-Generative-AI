{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqpsYn49QWSR"
      },
      "source": [
        "#Introducing Naive, Advanced, and Modular RAG\n",
        "\n",
        "Copyright 2024, Denis Rothman\n",
        "\n",
        "This notebook introduces Naïve, Advanced, and Modular RAG through basic educational examples.\n",
        "\n",
        "The Naïve, Advanced and modular RAG techniques offer flexibility in selecting retrieval strategies, allowing adaptation to various tasks and data characteristics.\n",
        "\n",
        "**Summary**\n",
        "\n",
        "**Part 1: Foundations and Basic Implementation**\n",
        "\n",
        "1.Environment setup for OpenAI API integration  \n",
        "2.Generator function using GPT models    \n",
        "3.Dataetup with a list of documents (db_records)  \n",
        "4.Query(user request)  \n",
        "\n",
        "**Part 2: Advanced Techniques and Evaluation**\n",
        "\n",
        "1.Retrieval metrics  \n",
        "2.Naive RAG  \n",
        "3.Advanced RAG  \n",
        "4.Modular RAG Retriever  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ICSQQ0ipxlR"
      },
      "source": [
        "# Part 1: Foundations and Basic Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o01-IM8bTc5f"
      },
      "source": [
        "# 1.The Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rag-driven-generative-ai v0.1.0\n",
            "├── deeplake v3.9.52\n",
            "│   ├── boto3 v1.40.49\n",
            "│   │   ├── botocore v1.40.49\n",
            "│   │   │   ├── jmespath v1.0.1\n",
            "│   │   │   ├── python-dateutil v2.9.0.post0\n",
            "│   │   │   │   └── six v1.16.0\n",
            "│   │   │   └── urllib3 v2.5.0\n",
            "│   │   ├── jmespath v1.0.1\n",
            "│   │   └── s3transfer v0.14.0\n",
            "│   │       └── botocore v1.40.49 (*)\n",
            "│   ├── click v8.3.0\n",
            "│   │   └── colorama v0.4.6\n",
            "│   ├── humbug v0.3.2\n",
            "│   │   └── requests v2.32.5\n",
            "│   │       ├── certifi v2025.10.5\n",
            "│   │       ├── charset-normalizer v3.4.4\n",
            "│   │       ├── idna v3.11\n",
            "│   │       └── urllib3 v2.5.0\n",
            "│   ├── lz4 v4.4.4\n",
            "│   ├── numpy v2.3.4\n",
            "│   ├── pathos v0.3.4\n",
            "│   │   ├── dill v0.4.0\n",
            "│   │   ├── multiprocess v0.70.18\n",
            "│   │   │   └── dill v0.4.0\n",
            "│   │   ├── pox v0.3.6\n",
            "│   │   └── ppft v1.7.7\n",
            "│   ├── pillow v10.4.0\n",
            "│   ├── pydantic v2.12.3\n",
            "│   │   ├── annotated-types v0.7.0\n",
            "│   │   ├── pydantic-core v2.41.4\n",
            "│   │   │   └── typing-extensions v4.15.0\n",
            "│   │   ├── typing-extensions v4.15.0\n",
            "│   │   └── typing-inspection v0.4.2\n",
            "│   │       └── typing-extensions v4.15.0\n",
            "│   ├── pyjwt v2.10.1\n",
            "│   ├── six v1.16.0\n",
            "│   └── tqdm v4.67.1\n",
            "│       └── colorama v0.4.6\n",
            "├── ipykernel v7.1.0\n",
            "│   ├── comm v0.2.3\n",
            "│   ├── debugpy v1.8.17\n",
            "│   ├── ipython v9.6.0\n",
            "│   │   ├── colorama v0.4.6\n",
            "│   │   ├── decorator v5.2.1\n",
            "│   │   ├── ipython-pygments-lexers v1.1.1\n",
            "│   │   │   └── pygments v2.19.2\n",
            "│   │   ├── jedi v0.19.2\n",
            "│   │   │   └── parso v0.8.5\n",
            "│   │   ├── matplotlib-inline v0.2.1\n",
            "│   │   │   └── traitlets v5.14.3\n",
            "│   │   ├── prompt-toolkit v3.0.52\n",
            "│   │   │   └── wcwidth v0.2.14\n",
            "│   │   ├── pygments v2.19.2\n",
            "│   │   ├── stack-data v0.6.3\n",
            "│   │   │   ├── asttokens v3.0.0\n",
            "│   │   │   ├── executing v2.2.1\n",
            "│   │   │   └── pure-eval v0.2.3\n",
            "│   │   └── traitlets v5.14.3\n",
            "│   ├── jupyter-client v8.6.3\n",
            "│   │   ├── jupyter-core v5.9.1\n",
            "│   │   │   ├── platformdirs v4.5.0\n",
            "│   │   │   └── traitlets v5.14.3\n",
            "│   │   ├── python-dateutil v2.9.0.post0 (*)\n",
            "│   │   ├── pyzmq v27.1.0\n",
            "│   │   ├── tornado v6.5.2\n",
            "│   │   └── traitlets v5.14.3\n",
            "│   ├── jupyter-core v5.9.1 (*)\n",
            "│   ├── matplotlib-inline v0.2.1 (*)\n",
            "│   ├── nest-asyncio v1.6.0\n",
            "│   ├── packaging v25.0\n",
            "│   ├── psutil v7.1.2\n",
            "│   ├── pyzmq v27.1.0\n",
            "│   ├── tornado v6.5.2\n",
            "│   └── traitlets v5.14.3\n",
            "├── nltk v3.9.2\n",
            "│   ├── click v8.3.0 (*)\n",
            "│   ├── joblib v1.5.2\n",
            "│   ├── regex v2025.10.23\n",
            "│   └── tqdm v4.67.1 (*)\n",
            "├── numpy v2.3.4\n",
            "├── openai v2.6.1\n",
            "│   ├── anyio v4.11.0\n",
            "│   │   ├── idna v3.11\n",
            "│   │   ├── sniffio v1.3.1\n",
            "│   │   └── typing-extensions v4.15.0\n",
            "│   ├── distro v1.9.0\n",
            "│   ├── httpx v0.28.1\n",
            "│   │   ├── anyio v4.11.0 (*)\n",
            "│   │   ├── certifi v2025.10.5\n",
            "│   │   ├── httpcore v1.0.9\n",
            "│   │   │   ├── certifi v2025.10.5\n",
            "│   │   │   └── h11 v0.16.0\n",
            "│   │   └── idna v3.11\n",
            "│   ├── jiter v0.11.1\n",
            "│   ├── pydantic v2.12.3 (*)\n",
            "│   ├── sniffio v1.3.1\n",
            "│   ├── tqdm v4.67.1 (*)\n",
            "│   └── typing-extensions v4.15.0\n",
            "├── pandas v2.3.3\n",
            "│   ├── numpy v2.3.4\n",
            "│   ├── python-dateutil v2.9.0.post0 (*)\n",
            "│   ├── pytz v2025.2\n",
            "│   └── tzdata v2025.2\n",
            "├── python-dotenv v1.2.1\n",
            "├── scikit-learn v1.7.2\n",
            "│   ├── joblib v1.5.2\n",
            "│   ├── numpy v2.3.4\n",
            "│   ├── scipy v1.16.3\n",
            "│   │   └── numpy v2.3.4\n",
            "│   └── threadpoolctl v3.6.0\n",
            "├── spacy v3.8.7\n",
            "│   ├── catalogue v2.0.10\n",
            "│   ├── cymem v2.0.11\n",
            "│   ├── jinja2 v3.1.6\n",
            "│   │   └── markupsafe v3.0.3\n",
            "│   ├── langcodes v3.5.0\n",
            "│   │   └── language-data v1.3.0\n",
            "│   │       └── marisa-trie v1.3.1\n",
            "│   ├── murmurhash v1.0.13\n",
            "│   ├── numpy v2.3.4\n",
            "│   ├── packaging v25.0\n",
            "│   ├── preshed v3.0.10\n",
            "│   │   ├── cymem v2.0.11\n",
            "│   │   └── murmurhash v1.0.13\n",
            "│   ├── pydantic v2.12.3 (*)\n",
            "│   ├── requests v2.32.5 (*)\n",
            "│   ├── setuptools v80.9.0\n",
            "│   ├── spacy-legacy v3.0.12\n",
            "│   ├── spacy-loggers v1.0.5\n",
            "│   ├── srsly v2.5.1\n",
            "│   │   └── catalogue v2.0.10\n",
            "│   ├── thinc v8.3.6\n",
            "│   │   ├── blis v1.3.0\n",
            "│   │   │   └── numpy v2.3.4\n",
            "│   │   ├── catalogue v2.0.10\n",
            "│   │   ├── confection v0.1.5\n",
            "│   │   │   ├── pydantic v2.12.3 (*)\n",
            "│   │   │   └── srsly v2.5.1 (*)\n",
            "│   │   ├── cymem v2.0.11\n",
            "│   │   ├── murmurhash v1.0.13\n",
            "│   │   ├── numpy v2.3.4\n",
            "│   │   ├── packaging v25.0\n",
            "│   │   ├── preshed v3.0.10 (*)\n",
            "│   │   ├── pydantic v2.12.3 (*)\n",
            "│   │   ├── setuptools v80.9.0\n",
            "│   │   ├── srsly v2.5.1 (*)\n",
            "│   │   └── wasabi v1.1.3\n",
            "│   │       └── colorama v0.4.6\n",
            "│   ├── tqdm v4.67.1 (*)\n",
            "│   ├── typer v0.20.0\n",
            "│   │   ├── click v8.3.0 (*)\n",
            "│   │   ├── rich v14.2.0\n",
            "│   │   │   ├── markdown-it-py v4.0.0\n",
            "│   │   │   │   └── mdurl v0.1.2\n",
            "│   │   │   └── pygments v2.19.2\n",
            "│   │   ├── shellingham v1.5.4\n",
            "│   │   └── typing-extensions v4.15.0\n",
            "│   ├── wasabi v1.1.3 (*)\n",
            "│   └── weasel v0.4.1\n",
            "│       ├── cloudpathlib v0.23.0\n",
            "│       ├── confection v0.1.5 (*)\n",
            "│       ├── packaging v25.0\n",
            "│       ├── pydantic v2.12.3 (*)\n",
            "│       ├── requests v2.32.5 (*)\n",
            "│       ├── smart-open v7.4.1\n",
            "│       │   └── wrapt v1.17.3\n",
            "│       ├── srsly v2.5.1 (*)\n",
            "│       ├── typer v0.20.0 (*)\n",
            "│       └── wasabi v1.1.3 (*)\n",
            "├── torch v2.9.0\n",
            "│   ├── filelock v3.20.0\n",
            "│   ├── fsspec v2025.9.0\n",
            "│   ├── jinja2 v3.1.6 (*)\n",
            "│   ├── networkx v3.5\n",
            "│   ├── setuptools v80.9.0\n",
            "│   ├── sympy v1.14.0\n",
            "│   │   └── mpmath v1.3.0\n",
            "│   └── typing-extensions v4.15.0\n",
            "└── transformers v4.57.1\n",
            "    ├── filelock v3.20.0\n",
            "    ├── huggingface-hub v0.36.0\n",
            "    │   ├── filelock v3.20.0\n",
            "    │   ├── fsspec v2025.9.0\n",
            "    │   ├── packaging v25.0\n",
            "    │   ├── pyyaml v6.0.3\n",
            "    │   ├── requests v2.32.5 (*)\n",
            "    │   ├── tqdm v4.67.1 (*)\n",
            "    │   └── typing-extensions v4.15.0\n",
            "    ├── numpy v2.3.4\n",
            "    ├── packaging v25.0\n",
            "    ├── pyyaml v6.0.3\n",
            "    ├── regex v2025.10.23\n",
            "    ├── requests v2.32.5 (*)\n",
            "    ├── safetensors v0.6.2\n",
            "    ├── tokenizers v0.22.1\n",
            "    │   └── huggingface-hub v0.36.0 (*)\n",
            "    └── tqdm v4.67.1 (*)\n",
            "\u001b[3m(*) Package tree already displayed\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2mResolved \u001b[1m146 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VCfbN0YwHbE",
        "outputId": "2ab71eb3-5c22-41b0-f871-cabac619527b"
      },
      "outputs": [],
      "source": [
        "# !pip install openai==1.107.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myXJn33zbqTR",
        "outputId": "ac51a798-8200-483b-cc95-b9db1215a330"
      },
      "outputs": [],
      "source": [
        "#API Key\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oefvqp21Ba07"
      },
      "outputs": [],
      "source": [
        "# f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "# API_KEY=f.readline().strip()\n",
        "# f.close()\n",
        "\n",
        "# #The OpenAI Key\n",
        "# import os\n",
        "# import openai\n",
        "# os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ API Key loaded: sk-proj-lq...\n"
          ]
        }
      ],
      "source": [
        "# API Key Setup using dotenv (for local development)\n",
        "# This replaces the Google Colab drive mount\n",
        "# Make sure you have a .env file in the project root with: OPENAI_API_KEY=your-key-here\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Verify the key is loaded (shows first few characters only for security)\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if api_key:\n",
        "    print(f\"✓ API Key loaded: {api_key[:10]}...\")\n",
        "else:\n",
        "    print(\"✗ WARNING: OPENAI_API_KEY not found in .env file!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ OpenAI API key configured successfully\n"
          ]
        }
      ],
      "source": [
        "# Set up OpenAI client with the API key from environment\n",
        "import openai\n",
        "\n",
        "# The API key is already loaded from .env via load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Verify setup\n",
        "if openai.api_key:\n",
        "    print(\"✓ OpenAI API key configured successfully\")\n",
        "else:\n",
        "    print(\"✗ ERROR: OpenAI API key not set!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuZ7jr4Rs36U"
      },
      "source": [
        "# 2.The Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qwCNTW9fs36U"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "gptmodel=\"gpt-4o\"\n",
        "\n",
        "def call_llm_with_full_text(itext):\n",
        "    # Join all lines to form a single string\n",
        "    text_input = '\\n'.join(itext)\n",
        "    prompt = f\"Please elaborate on the following content:\\n{text_input}\"\n",
        "\n",
        "    try:\n",
        "      response = client.chat.completions.create(\n",
        "         model=gptmodel,\n",
        "         messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"1.You can explain read the input and answer in detail\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "         ],\n",
        "         temperature=0.1  # Add the temperature parameter here and other parameters you need\n",
        "        )\n",
        "      return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVKe9VF0HIHJ"
      },
      "source": [
        "## Formatted response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oG8I2Kb2HFhL"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_formatted_response(response):\n",
        "    # Define the width for wrapping the text\n",
        "    wrapper = textwrap.TextWrapper(width=80)  # Set to 80 columns wide, but adjust as needed\n",
        "    wrapped_text = wrapper.fill(text=response)\n",
        "\n",
        "    # Print the formatted response with a header and footer\n",
        "    print(\"Response:\")\n",
        "    print(\"---------------\")\n",
        "    print(wrapped_text)\n",
        "    print(\"---------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv1ExPiZdJRL"
      },
      "source": [
        " # 3.The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "45CFxG4Fgcju"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        }
      ],
      "source": [
        "db_records = [\n",
        "    \"Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP).\",\n",
        "    \"It innovatively combines the capabilities of neural network-based language models with retrieval systems to enhance the generation of text, making it more accurate, informative, and contextually relevant.\",\n",
        "    \"This methodology leverages the strengths of both generative and retrieval architectures to tackle complex tasks that require not only linguistic fluency but also factual correctness and depth of knowledge.\",\n",
        "    \"At the core of Retrieval Augmented Generation (RAG) is a generative model, typically a transformer-based neural network, similar to those used in models like GPT (Generative Pre-trained Transformer) or BERT (Bidirectional Encoder Representations from Transformers).\",\n",
        "    \"This component is responsible for producing coherent and contextually appropriate language outputs based on a mixture of input prompts and additional information fetched by the retrieval component.\",\n",
        "    \"Complementing the language model is the retrieval system, which is usually built on a database of documents or a corpus of texts.\",\n",
        "    \"This system uses techniques from information retrieval to find and fetch documents that are relevant to the input query or prompt.\",\n",
        "    \"The mechanism of relevance determination can range from simple keyword matching to more complex semantic search algorithms which interpret the meaning behind the query to find the best matches.\",\n",
        "    \"This component merges the outputs from the language model and the retrieval system.\",\n",
        "    \"It effectively synthesizes the raw data fetched by the retrieval system into the generative process of the language model.\",\n",
        "    \"The integrator ensures that the information from the retrieval system is seamlessly incorporated into the final text output, enhancing the model's ability to generate responses that are not only fluent and grammatically correct but also rich in factual details and context-specific nuances.\",\n",
        "    \"When a query or prompt is received, the system first processes it to understand the requirement or the context.\",\n",
        "    \"Based on the processed query, the retrieval system searches through its database to find relevant documents or information snippets.\",\n",
        "    \"This retrieval is guided by the similarity of content in the documents to the query, which can be determined through various techniques like vector embeddings or semantic similarity measures.\",\n",
        "    \"The retrieved documents are then fed into the language model.\",\n",
        "    \"In some implementations, this integration happens at the token level, where the model can access and incorporate specific pieces of information from the retrieved texts dynamically as it generates each part of the response.\",\n",
        "    \"The language model, now augmented with direct access to retrieved information, generates a response.\",\n",
        "    \"This response is not only influenced by the training of the model but also by the specific facts and details contained in the retrieved documents, making it more tailored and accurate.\",\n",
        "    \"By directly incorporating information from external sources, Retrieval Augmented Generation (RAG) models can produce responses that are more factual and relevant to the given query.\",\n",
        "    \"This is particularly useful in domains like medical advice, technical support, and other areas where precision and up-to-date knowledge are crucial.\",\n",
        "    \"Retrieval Augmented Generation (RAG) systems can dynamically adapt to new information since they retrieve data in real-time from their databases.\",\n",
        "    \"This allows them to remain current with the latest knowledge and trends without needing frequent retraining.\",\n",
        "    \"With access to a wide range of documents, Retrieval Augmented Generation (RAG) systems can provide detailed and nuanced answers that a standalone language model might not be capable of generating based solely on its pre-trained knowledge.\",\n",
        "    \"While Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes with its challenges.\",\n",
        "    \"These include the complexity of integrating retrieval and generation systems, the computational overhead associated with real-time data retrieval, and the need for maintaining a large, up-to-date, and high-quality database of retrievable texts.\",\n",
        "    \"Furthermore, ensuring the relevance and accuracy of the retrieved information remains a significant challenge, as does managing the potential for introducing biases or errors from the external sources.\",\n",
        "    \"In summary, Retrieval Augmented Generation represents a significant advancement in the field of artificial intelligence, merging the best of retrieval-based and generative technologies to create systems that not only understand and generate natural language but also deeply comprehend and utilize the vast amounts of information available in textual form.\",\n",
        "    \"A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
        "]\n",
        "print(len(db_records))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIQ7NK92g7EC",
        "outputId": "3c1a786d-4e8f-4cb4-9ccd-573f8c06876b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach\n",
            "in the field of artificial intelligence, particularly within the realm of\n",
            "natural language processing (NLP). It innovatively combines the capabilities of\n",
            "neural network-based language models with retrieval systems to enhance the\n",
            "generation of text, making it more accurate, informative, and contextually\n",
            "relevant. This methodology leverages the strengths of both generative and\n",
            "retrieval architectures to tackle complex tasks that require not only linguistic\n",
            "fluency but also factual correctness and depth of knowledge. At the core of\n",
            "Retrieval Augmented Generation (RAG) is a generative model, typically a\n",
            "transformer-based neural network, similar to those used in models like GPT\n",
            "(Generative Pre-trained Transformer) or BERT (Bidirectional Encoder\n",
            "Representations from Transformers). This component is responsible for producing\n",
            "coherent and contextually appropriate language outputs based on a mixture of\n",
            "input prompts and additional information fetched by the retrieval component.\n",
            "Complementing the language model is the retrieval system, which is usually built\n",
            "on a database of documents or a corpus of texts. This system uses techniques\n",
            "from information retrieval to find and fetch documents that are relevant to the\n",
            "input query or prompt. The mechanism of relevance determination can range from\n",
            "simple keyword matching to more complex semantic search algorithms which\n",
            "interpret the meaning behind the query to find the best matches. This component\n",
            "merges the outputs from the language model and the retrieval system. It\n",
            "effectively synthesizes the raw data fetched by the retrieval system into the\n",
            "generative process of the language model. The integrator ensures that the\n",
            "information from the retrieval system is seamlessly incorporated into the final\n",
            "text output, enhancing the model's ability to generate responses that are not\n",
            "only fluent and grammatically correct but also rich in factual details and\n",
            "context-specific nuances. When a query or prompt is received, the system first\n",
            "processes it to understand the requirement or the context. Based on the\n",
            "processed query, the retrieval system searches through its database to find\n",
            "relevant documents or information snippets. This retrieval is guided by the\n",
            "similarity of content in the documents to the query, which can be determined\n",
            "through various techniques like vector embeddings or semantic similarity\n",
            "measures. The retrieved documents are then fed into the language model. In some\n",
            "implementations, this integration happens at the token level, where the model\n",
            "can access and incorporate specific pieces of information from the retrieved\n",
            "texts dynamically as it generates each part of the response. The language model,\n",
            "now augmented with direct access to retrieved information, generates a response.\n",
            "This response is not only influenced by the training of the model but also by\n",
            "the specific facts and details contained in the retrieved documents, making it\n",
            "more tailored and accurate. By directly incorporating information from external\n",
            "sources, Retrieval Augmented Generation (RAG) models can produce responses that\n",
            "are more factual and relevant to the given query. This is particularly useful in\n",
            "domains like medical advice, technical support, and other areas where precision\n",
            "and up-to-date knowledge are crucial. Retrieval Augmented Generation (RAG)\n",
            "systems can dynamically adapt to new information since they retrieve data in\n",
            "real-time from their databases. This allows them to remain current with the\n",
            "latest knowledge and trends without needing frequent retraining. With access to\n",
            "a wide range of documents, Retrieval Augmented Generation (RAG) systems can\n",
            "provide detailed and nuanced answers that a standalone language model might not\n",
            "be capable of generating based solely on its pre-trained knowledge. While\n",
            "Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes\n",
            "with its challenges. These include the complexity of integrating retrieval and\n",
            "generation systems, the computational overhead associated with real-time data\n",
            "retrieval, and the need for maintaining a large, up-to-date, and high-quality\n",
            "database of retrievable texts. Furthermore, ensuring the relevance and accuracy\n",
            "of the retrieved information remains a significant challenge, as does managing\n",
            "the potential for introducing biases or errors from the external sources. In\n",
            "summary, Retrieval Augmented Generation represents a significant advancement in\n",
            "the field of artificial intelligence, merging the best of retrieval-based and\n",
            "generative technologies to create systems that not only understand and generate\n",
            "natural language but also deeply comprehend and utilize the vast amounts of\n",
            "information available in textual form. A RAG vector store is a database or\n",
            "dataset that contains vectorized data points.\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "paragraph = ' '.join(db_records)\n",
        "wrapped_text = textwrap.fill(paragraph, width=80)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL7cHuuLhQ5w"
      },
      "source": [
        "# 4.The Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qARk6gtohSXW"
      },
      "outputs": [],
      "source": [
        "query = \"define a rag store\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iITo3QIF7yeK"
      },
      "source": [
        "Generation without augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXBILWI47yeM",
        "outputId": "c81ac445-5845-403e-d8d0-c12dd0fe97c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "It seems like you've provided a sequence of letters that, when combined, form\n",
            "the phrase \"define a rag store.\" Let's break down and elaborate on this phrase:\n",
            "1. **Define**: This is a verb that means to explain the meaning of a word or\n",
            "concept. In this context, it suggests that you are looking for an explanation or\n",
            "description of what a \"rag store\" is.  2. **A**: This is an indefinite article\n",
            "used in English to refer to a non-specific item or entity. It precedes a noun\n",
            "and indicates that the noun is singular and not previously specified.  3.\n",
            "**Rag**: This noun typically refers to a piece of old, often torn, cloth. Rags\n",
            "are usually used for cleaning or wiping purposes. In a broader sense, \"rag\" can\n",
            "also refer to low-quality or discarded textiles.  4. **Store**: This noun refers\n",
            "to a place where goods are sold to the public. It can be a physical location or,\n",
            "in modern contexts, an online platform.  Putting it all together, a \"rag store\"\n",
            "would be a retail establishment that specializes in selling rags or similar\n",
            "textile products. Such stores might offer a variety of cloths for cleaning,\n",
            "crafting, or other purposes. They could cater to both individual consumers and\n",
            "businesses that require bulk quantities of cleaning materials. In some contexts,\n",
            "a rag store might also sell recycled or repurposed textiles, aligning with\n",
            "sustainable practices.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(query)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11HLkKQMqaDt"
      },
      "source": [
        "# Part 2: Advanced Techniques and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMGuZg1WiaUE"
      },
      "source": [
        "# 1.Retrieval Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHN6s7wZirQL"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_GLECrTQirQN"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        use_idf=True,\n",
        "        norm='l2',\n",
        "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
        "        sublinear_tf=True,   # Apply sublinear TF scaling\n",
        "        analyzer='word'      # You could also experiment with 'char' or 'char_wb' for character-level features\n",
        "    )\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "    return similarity[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTJOi-jrjI5A"
      },
      "source": [
        "## Enhanced Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnmPG9UWjJXD",
        "outputId": "b7a8db4c-9b16-4a17-cc7f-679d67983912"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    lemmatized_words = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        lemmatized_words.append(token.lemma_)\n",
        "    return lemmatized_words\n",
        "\n",
        "def expand_with_synonyms(words):\n",
        "    expanded_words = words.copy()\n",
        "    for word in words:\n",
        "        expanded_words.extend(get_synonyms(word))\n",
        "    return expanded_words\n",
        "\n",
        "def calculate_enhanced_similarity(text1, text2):\n",
        "    # Preprocess and tokenize texts\n",
        "    words1 = preprocess_text(text1)\n",
        "    words2 = preprocess_text(text2)\n",
        "\n",
        "    # Expand with synonyms\n",
        "    words1_expanded = expand_with_synonyms(words1)\n",
        "    words2_expanded = expand_with_synonyms(words2)\n",
        "\n",
        "    # Count word frequencies\n",
        "    freq1 = Counter(words1_expanded)\n",
        "    freq2 = Counter(words2_expanded)\n",
        "\n",
        "    # Create a set of all unique words\n",
        "    unique_words = set(freq1.keys()).union(set(freq2.keys()))\n",
        "\n",
        "    # Create frequency vectors\n",
        "    vector1 = [freq1[word] for word in unique_words]\n",
        "    vector2 = [freq2[word] for word in unique_words]\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    vector1 = np.array(vector1)\n",
        "    vector2 = np.array(vector2)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "\n",
        "    return cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFqh9rr81SUn"
      },
      "source": [
        "# 2.Naive RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu8vteKmS_qO"
      },
      "source": [
        "## Keyword search and matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY1JU0Ush_l4",
        "outputId": "cd9426f3-43d3-40a7-acc6-f63b2d6bb230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Keyword Score: 3\n",
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def find_best_match_keyword_search(query, db_records):\n",
        "    best_score = 0\n",
        "    best_record = None\n",
        "\n",
        "    # Split the query into individual keywords\n",
        "    query_keywords = set(query.lower().split())\n",
        "\n",
        "    # Iterate through each record in db_records\n",
        "    for record in db_records:\n",
        "        # Split the record into keywords\n",
        "        record_keywords = set(record.lower().split())\n",
        "\n",
        "        # Calculate the number of common keywords\n",
        "        common_keywords = query_keywords.intersection(record_keywords)\n",
        "        current_score = len(common_keywords)\n",
        "\n",
        "        # Update the best score and record if the current score is higher\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_record = record\n",
        "\n",
        "    return best_score, best_record\n",
        "\n",
        "# Assuming 'query' and 'db_records' are defined in previous cells in your Colab notebook\n",
        "best_keyword_score, best_matching_record = find_best_match_keyword_search(query, db_records)\n",
        "\n",
        "print(f\"Best Keyword Score: {best_keyword_score}\")\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oak-3k_dkzC3"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blcPOIaHkzC4",
        "outputId": "a9dc44ef-b480-49b6-eb48-b41002bd654a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Cosine Similarity Score: 0.126\n"
          ]
        }
      ],
      "source": [
        "# Cosine Similarity\n",
        "score = calculate_cosine_similarity(query, best_matching_record)\n",
        "print(f\"Best Cosine Similarity Score: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OW0l24IkzC5",
        "outputId": "f24affb1-a7d2-49d7-e1ed-47c8a6970ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity: 0.642\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(f\"Enhanced Similarity: {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2zKQhiO0Fcr"
      },
      "source": [
        "## Augmented input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "r_7ymSxG0Fcs"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+ \": \"+ best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NTfxzum0PT2",
        "outputId": "42979230-f964-47c2-9156-e37365ed96a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ui8wH4k3_g4"
      },
      "source": [
        "## Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh8BsnUy0Fcs",
        "outputId": "82db2df0-5107-4fea-89ef-ca52ccfd360e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "An ARAG vector store, or more generally a vector store, is a specialized type of\n",
            "database or dataset designed to store and manage vectorized data points. Here's\n",
            "a detailed explanation of what this entails:  1. **Vectorized Data Points**: In\n",
            "the context of machine learning and data science, data is often represented in\n",
            "the form of vectors. A vector is essentially an array of numbers that can\n",
            "represent various types of data, such as text, images, or any other form of\n",
            "information that can be numerically encoded. For example, in natural language\n",
            "processing, words or sentences can be converted into vectors using techniques\n",
            "like word embeddings (e.g., Word2Vec, GloVe) or contextual embeddings (e.g.,\n",
            "BERT, GPT).  2. **Purpose of a Vector Store**: The primary purpose of a vector\n",
            "store is to efficiently store and retrieve these high-dimensional vectors. This\n",
            "is crucial for tasks that involve similarity search, clustering, and other\n",
            "operations that require comparing vectors to find the most similar ones. For\n",
            "instance, in a recommendation system, a vector store can be used to find items\n",
            "that are similar to a user's preferences.  3. **Structure and Functionality**: A\n",
            "vector store is optimized for operations that involve high-dimensional data. It\n",
            "typically supports functionalities such as:    - **Indexing**: Creating an index\n",
            "to quickly retrieve vectors based on similarity measures.    - **Similarity\n",
            "Search**: Finding vectors that are closest to a given query vector using\n",
            "distance metrics like cosine similarity or Euclidean distance.    -\n",
            "**Scalability**: Handling large volumes of vector data efficiently, which is\n",
            "essential for applications dealing with big data.  4. **Applications**: Vector\n",
            "stores are widely used in various applications, including:    - **Search\n",
            "Engines**: Enhancing search capabilities by finding documents or images similar\n",
            "to a query.    - **Recommendation Systems**: Suggesting products, movies, or\n",
            "content based on user preferences.    - **Natural Language Processing**: Tasks\n",
            "like semantic search, document clustering, and topic modeling.  5. **Examples of\n",
            "Vector Stores**: There are several tools and platforms designed specifically for\n",
            "managing vector data, such as FAISS (Facebook AI Similarity Search), Annoy\n",
            "(Approximate Nearest Neighbors Oh Yeah), and commercial solutions like Pinecone\n",
            "and Weaviate.  In summary, an ARAG vector store is a crucial component in modern\n",
            "data-driven applications, enabling efficient storage, retrieval, and\n",
            "manipulation of vectorized data to support various machine learning and AI\n",
            "tasks.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJH2__0iTUr1"
      },
      "source": [
        "# 3.Advanced RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awyjcn35jFiy"
      },
      "source": [
        "## 3.1.Vector search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD8_758kkq3h"
      },
      "source": [
        "### Search function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FCBbY4qLc8qh"
      },
      "outputs": [],
      "source": [
        "def find_best_match(text_input, records):\n",
        "    best_score = 0\n",
        "    best_record = None\n",
        "    for record in records:\n",
        "        current_score = calculate_cosine_similarity(text_input, record)\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_record = record\n",
        "    return best_score, best_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RG1iM-U33OCg"
      },
      "outputs": [],
      "source": [
        "best_similarity_score, best_matching_record = find_best_match(query, db_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLa9NQ4Cm_YQ",
        "outputId": "df567b6a-1b4a-4f6a-a913-60e3edb4883a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A60QoOA3jf9j"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIUh-38knHLI",
        "outputId": "7b8e0ee8-827f-4fa4-c9fe-2fdec7b175f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Cosine Similarity Score: 0.126\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQopW_FSjBSr",
        "outputId": "cc6cdfd2-0f3f-4c09-bd04-7c43a3cc8649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity:, 0.642\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, best_matching_record)\n",
        "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51fZC6Oe2G9E"
      },
      "source": [
        "### Augmented input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "4dcnK7OGx5e6"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+\": \"+best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3uk-91x049J",
        "outputId": "928f5eda-d894-4830-a9c7-d04d461bb19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFDF6hbi2LF9"
      },
      "source": [
        "### Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJC-mA5ftxFU",
        "outputId": "c67b9a00-78c2-4beb-b88a-127db37f0859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "An \"ARAG vector store\" refers to a specialized type of database or dataset\n",
            "designed to store and manage vectorized data points. Let's break down the\n",
            "concept further:  1. **Vectorized Data Points**: In the context of data science\n",
            "and machine learning, vectorization is the process of converting data into a\n",
            "numerical format that can be easily processed by algorithms. Each data point is\n",
            "represented as a vector, which is essentially an array of numbers. These vectors\n",
            "can represent various types of data, such as text, images, or any other form of\n",
            "information that can be encoded numerically.  2. **Purpose of a Vector Store**:\n",
            "The primary purpose of a vector store is to efficiently store, retrieve, and\n",
            "manage these vectorized data points. This is particularly useful in applications\n",
            "that require fast similarity searches, such as recommendation systems, natural\n",
            "language processing tasks, and image recognition.  3. **Applications**: Vector\n",
            "stores are commonly used in machine learning and artificial intelligence\n",
            "applications where large volumes of data need to be processed and analyzed. They\n",
            "enable quick retrieval of similar data points, which is crucial for tasks like\n",
            "clustering, classification, and nearest neighbor searches.  4. **Benefits**: By\n",
            "using a vector store, organizations can handle large-scale data more\n",
            "effectively. It allows for efficient querying and retrieval of data based on\n",
            "similarity, which can significantly enhance the performance of AI models and\n",
            "systems.  5. **Implementation**: Vector stores can be implemented using various\n",
            "technologies and frameworks, depending on the specific requirements of the\n",
            "application. They often involve the use of specialized indexing techniques to\n",
            "optimize the storage and retrieval processes.  In summary, an ARAG vector store\n",
            "is a crucial component in the field of data science, providing a structured way\n",
            "to manage and utilize vectorized data for various analytical and machine\n",
            "learning tasks.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7djpPBpm0M2"
      },
      "source": [
        "## 3.2.Index-based search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyDUhy_1lBfT"
      },
      "source": [
        "### Search Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRarT_fym2XC",
        "outputId": "af09947c-5800-4b97-d357-0a3c2c941b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(records)\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "def find_best_match(query, vectorizer, tfidf_matrix):\n",
        "    query_tfidf = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_tfidf, tfidf_matrix)\n",
        "    best_index = similarities.argmax()  # Get the index of the highest similarity score\n",
        "    best_score = similarities[0, best_index]\n",
        "    return best_score, best_index\n",
        "\n",
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)\n",
        "\n",
        "best_similarity_score, best_index = find_best_match(query, vectorizer, tfidf_matrix)\n",
        "best_matching_record = db_records[best_index]\n",
        "\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt3iBtJFj4sa"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoNUQqx5j3r4",
        "outputId": "1a531b09-9e22-457b-a610-9108ed06557c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Cosine Similarity Score: 0.407\n",
            "Best Index: 27\n",
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cosine Similarity\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
        "print(f\"Best Index: {best_index}\")\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg910Mhuj3sO",
        "outputId": "bd77ca3e-0769-42a5-9472-7ffda3961ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity:, 0.642\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubm0DTxKeqR9"
      },
      "source": [
        "Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbokQ2eacHjM",
        "outputId": "3f84b618-eba1-4c54-c89b-fa18df9dd336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     ability    access  accuracy  accurate     adapt  additional  advancement  \\\n",
            "0   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "1   0.000000  0.000000  0.000000  0.216364  0.000000    0.000000     0.000000   \n",
            "2   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "3   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "4   0.000000  0.000000  0.000000  0.000000  0.000000    0.236479     0.000000   \n",
            "5   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "6   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "7   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "8   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "9   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "10  0.186734  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "11  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "12  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "13  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "14  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "15  0.000000  0.172624  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "16  0.000000  0.317970  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "17  0.000000  0.000000  0.000000  0.206861  0.000000    0.000000     0.000000   \n",
            "18  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "19  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "20  0.000000  0.000000  0.000000  0.000000  0.275802    0.000000     0.000000   \n",
            "21  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "22  0.000000  0.174772  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "23  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "24  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "25  0.000000  0.000000  0.228743  0.000000  0.000000    0.000000     0.000000   \n",
            "26  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.173327   \n",
            "27  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "\n",
            "      advice  algorithms    allows  ...    vector  vectorized      when  \\\n",
            "0   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "1   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "2   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "3   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "4   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "5   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "6   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "7   0.000000    0.220687  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "8   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "9   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "10  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "11  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.295573   \n",
            "12  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "13  0.000000    0.000000  0.000000  ...  0.200131     0.00000  0.000000   \n",
            "14  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "15  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "16  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "17  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "18  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "19  0.244401    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "20  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "21  0.000000    0.000000  0.291503  ...  0.000000     0.00000  0.000000   \n",
            "22  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "23  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "24  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "25  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "26  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "27  0.000000    0.000000  0.000000  ...  0.307719     0.34589  0.000000   \n",
            "\n",
            "       where     which    while     wide      with    within   without  \n",
            "0   0.000000  0.000000  0.00000  0.00000  0.000000  0.260582  0.000000  \n",
            "1   0.000000  0.000000  0.00000  0.00000  0.160278  0.000000  0.000000  \n",
            "2   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "3   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "4   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "5   0.000000  0.247710  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "6   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "7   0.000000  0.179053  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "8   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "9   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "10  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "11  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "12  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "13  0.000000  0.182517  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "14  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "15  0.189283  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "16  0.000000  0.000000  0.00000  0.00000  0.258278  0.000000  0.000000  \n",
            "17  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "18  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "19  0.217430  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "20  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "21  0.000000  0.000000  0.00000  0.00000  0.192110  0.000000  0.291503  \n",
            "22  0.000000  0.000000  0.00000  0.21541  0.141963  0.000000  0.000000  \n",
            "23  0.000000  0.000000  0.32932  0.00000  0.217033  0.000000  0.000000  \n",
            "24  0.000000  0.000000  0.00000  0.00000  0.134513  0.000000  0.000000  \n",
            "25  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "26  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "27  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "\n",
            "[28 rows x 297 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(records)\n",
        "\n",
        "    # Convert the TF-IDF matrix to a DataFrame for display purposes\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Display the DataFrame\n",
        "    print(tfidf_df)\n",
        "\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dABZ12Bkugtt"
      },
      "source": [
        "### Augmented input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "1w4wppuA4eNn"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+\": \"+best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNozI65K4e7u",
        "outputId": "e4a2dec1-65dc-44e1-f80b-2661f7914416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU998zkD4hpD"
      },
      "source": [
        "### Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy9X-l_Iugtt",
        "outputId": "644c0da4-0dca-4582-bb79-5090652976b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "An \"ARAG vector store\" refers to a specialized type of database or dataset\n",
            "designed to store and manage vectorized data points. Let's break down the\n",
            "concept further:  1. **Vectorized Data Points**: In the context of machine\n",
            "learning and data science, data is often represented as vectors. A vector is\n",
            "essentially an array of numbers that can represent various types of data, such\n",
            "as text, images, or any other form of information that can be numerically\n",
            "encoded. For example, in natural language processing, words or sentences can be\n",
            "converted into vectors using techniques like word embeddings (e.g., Word2Vec,\n",
            "GloVe) or sentence embeddings.  2. **Purpose of a Vector Store**: The primary\n",
            "purpose of a vector store is to efficiently store and retrieve these vectorized\n",
            "representations. This is crucial for tasks that involve similarity search,\n",
            "clustering, or any operation that requires comparing data points based on their\n",
            "vector representations.  3. **Applications**: Vector stores are widely used in\n",
            "applications such as recommendation systems, search engines, and any system that\n",
            "requires fast and efficient retrieval of similar items. For instance, in a\n",
            "recommendation system, a vector store can help quickly find items similar to a\n",
            "user's preferences by comparing vector distances.  4. **ARAG Vector Store**:\n",
            "While the term \"ARAG vector store\" isn't widely recognized in the literature, it\n",
            "could refer to a specific implementation or a proprietary system designed to\n",
            "handle vectorized data. The key characteristics would likely include optimized\n",
            "storage for high-dimensional vectors, efficient indexing for fast retrieval, and\n",
            "support for operations like nearest neighbor search.  In summary, an ARAG vector\n",
            "store is a system designed to manage and utilize vectorized data efficiently,\n",
            "enabling various applications that rely on understanding and processing complex\n",
            "data representations.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWEvzcDHTX6i"
      },
      "source": [
        "# 4.Modular RAG\n",
        "\n",
        "Modular RAG can combine methods. For example:\n",
        "\n",
        "**keyword search**:Searches through each document to find the one that best matches the keyword(s).\n",
        "\n",
        "**vector search**: Searches through each document and calculates similarity.\n",
        "\n",
        "**indexed search**: Uses a precomputed index (TF-IDF matrix) to compute cosine similarities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv-VqmLf3EQ9"
      },
      "source": [
        "**October 25, 2025 update**\n",
        "\n",
        "`self.documents` is initialized in the fit method to hold the records used for searching and enable the `keyword_search` function to access them without error.\n",
        "\n",
        "**Note on Vector search**\n",
        "\n",
        "In this case, the `def vector_search(self, query):` uses `tfidf_matrix`to increase the vector search performance.\n",
        "\n",
        "The `def vector_search(self, query):` function could use a brute-force method as implemented in `Section 3.1.Vector search` of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "18wmqwJd4o62"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class RetrievalComponent:\n",
        "    def __init__(self, method='vector'):\n",
        "        self.method = method\n",
        "        if self.method == 'vector' or self.method == 'indexed':\n",
        "            self.vectorizer = TfidfVectorizer()\n",
        "            self.tfidf_matrix = None\n",
        "\n",
        "    def fit(self, records):\n",
        "      self.documents = records  # Initialize self.documents here\n",
        "      if self.method == 'vector' or self.method == 'indexed':\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(records)\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        if self.method == 'keyword':\n",
        "            return self.keyword_search(query)\n",
        "        elif self.method == 'vector':\n",
        "            return self.vector_search(query)\n",
        "        elif self.method == 'indexed':\n",
        "            return self.indexed_search(query)\n",
        "\n",
        "    def keyword_search(self, query):\n",
        "        best_score = 0\n",
        "        best_record = None\n",
        "        query_keywords = set(query.lower().split())\n",
        "        for index, doc in enumerate(self.documents):\n",
        "            doc_keywords = set(doc.lower().split())\n",
        "            common_keywords = query_keywords.intersection(doc_keywords)\n",
        "            score = len(common_keywords)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_record = self.documents[index]\n",
        "        return best_record\n",
        "\n",
        "    def vector_search(self, query):\n",
        "        query_tfidf = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
        "        best_index = similarities.argmax()\n",
        "        return db_records[best_index]\n",
        "\n",
        "    def indexed_search(self, query):\n",
        "        # Assuming the tfidf_matrix is precomputed and stored\n",
        "        query_tfidf = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
        "        best_index = similarities.argmax()\n",
        "        return db_records[best_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qHm4saJ8cGk"
      },
      "source": [
        "### Modular RAG Strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kvhIOdY8amp",
        "outputId": "0e136233-8027-4294-b552-e5e966e032df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Usage example\n",
        "retrieval = RetrievalComponent(method='vector')  # Choose from 'keyword', 'vector', 'indexed'\n",
        "retrieval.fit(db_records)\n",
        "best_matching_record = retrieval.retrieve(query)\n",
        "\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgxXdqzvkYDk"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COyYme4IkYDx",
        "outputId": "09a2cf28-18c7-469a-fd7e-983175863bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Cosine Similarity Score: 0.407\n",
            "Response:\n",
            "---------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cosine Similarity\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
        "print_formatted_response(best_matching_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YRTpIpzkYDx",
        "outputId": "32636fd8-a921-4c98-9c69-3cb22bb27023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity: 0.641582812483307\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(\"Enhanced Similarity:\", similarity_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TaQa7Dc7JwT"
      },
      "source": [
        "### Augmented Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "X-hKjhIU7Jwg"
      },
      "outputs": [],
      "source": [
        "augmented_input=query+ \" \"+ best_matching_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhSO-fyZ7Jwg",
        "outputId": "7660703c-0626-4762-b665-644a0dc8f34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "define a rag store A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_formatted_response(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkyYx_MC7Jwg"
      },
      "source": [
        "### Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "---------------\n",
            "Certainly! Let's break down the concept of an \"ARAG vector store\" and what it\n",
            "means to have a database or dataset containing vectorized data points.  ### ARAG\n",
            "Vector Store  1. **ARAG**: While \"ARAG\" isn't a standard acronym in the context\n",
            "of vector stores, it could potentially refer to a specific implementation,\n",
            "framework, or proprietary technology related to vector storage. Without\n",
            "additional context, it's challenging to define precisely what \"ARAG\" stands for.\n",
            "However, in general terms, it could be a name or brand associated with a\n",
            "particular vector storage solution.  2. **Vector Store**: A vector store is a\n",
            "specialized database or storage system designed to handle and manage vectorized\n",
            "data. Vectors are mathematical representations of data points, often used in\n",
            "machine learning, data science, and artificial intelligence. They are typically\n",
            "arrays of numbers that represent features or characteristics of the data.  ###\n",
            "Vectorized Data Points  1. **Vectorization**: This is the process of converting\n",
            "data into a numerical format that can be easily processed by machine learning\n",
            "algorithms. For example, text data can be vectorized using techniques like word\n",
            "embeddings (e.g., Word2Vec, GloVe) or sentence embeddings, where each word or\n",
            "sentence is represented as a vector of numbers.  2. **Data Points**: In the\n",
            "context of a vector store, data points refer to individual pieces of data that\n",
            "have been transformed into vectors. Each data point is represented as a vector,\n",
            "capturing its essential features in a numerical form.  ### Purpose and Use Cases\n",
            "1. **Efficient Retrieval**: Vector stores are optimized for efficiently\n",
            "retrieving and querying vectorized data. This is particularly useful in\n",
            "applications like similarity search, where you want to find data points that are\n",
            "similar to a given query vector.  2. **Machine Learning and AI**: Vector stores\n",
            "are commonly used in machine learning and AI applications, where data needs to\n",
            "be processed in a numerical format. They facilitate tasks such as clustering,\n",
            "classification, and recommendation systems.  3. **Scalability**: These stores\n",
            "are designed to handle large volumes of vector data, making them suitable for\n",
            "big data applications where scalability and performance are critical.  In\n",
            "summary, an \"ARAG vector store\" refers to a system or solution that manages and\n",
            "stores vectorized data points, enabling efficient retrieval and processing of\n",
            "data in numerical form. This is essential for various applications in machine\n",
            "learning, AI, and data science, where data needs to be represented as vectors\n",
            "for analysis and computation.\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
